<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>ISAD - Posts and Anouncements</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">

  <!-- Custom styles for this template -->
  <link href="css/clean-blog.min.css" rel="stylesheet">

</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="navbar-collapse collapse w-100 order-1 order-md-0 dual-collapse2">
      <!-- nothing left aligned -->
    </div>

    <div class="collapse navbar-collapse mx-auto order-0" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="about.html">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="post.html">Anouncements</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="publications.html">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="researchers.html">Researchers</a>
        </li>
      </ul>
    </div>

    <div class="navbar-collapse collapse w-100 order-3 dual-collapse2">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a href="http://www.dfg.de" target="_blank" style="padding-right:5px">
            <img src="img/logo_dfg.svg" style="height:25px" alt="DFG">
          </a>
          <a href="https://www.audiolabs-erlangen.de/fau/professor/mueller" target="_blank" style="padding:5px">
            <img src="img/logo_fau.svg" style="height:25px" alt="FAU">
          </a>
          <a href="https://www.audiolabs-erlangen.de" target="_blank" style="padding:5px">
            <img src="img/logo_alabs.svg" style="height:25px" alt="AudioLabs">
          </a>
          <a href="https://www.idmt.fraunhofer.de/" target="_blank" style="padding:5px">
            <img src="img/logo_idmt.svg" style="height:25px" alt="IDMT">
          </a>
        </li>
      </ul>
    </div>
  </nav>

  <!-- Page Header -->
  <header class="masthead" style="background-image: url('img/home_without_logo.png')">
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="page-heading">
            <h2>News about ISAD</h2>
            <span class="subheading"></span>
          </div>
        </div>
      </div>
    </div>
  </header>

  <!-- Post Content -->
  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="ISMIR-2019">ISMIR 2019</h2>

          <blockquote class="blockquote">Two papers from the ISAD project have been accepted for the 20th Conference of the International Society for Music Information Retrieval (ISMIR 2019) in Delft, NL.</blockquote>
          <ul>
            <li>The paper titled "Investigating CNN-Based Instrument Family Recognition for Western Classical Music Recordings" analyzes the influence of data normalization, patch pre-processing and augmentation techniques on the generalization capabilities of CNN models.
                Experiments are conducted on three datasets covering different levels of timbral complexity (isolated notes, isolated melodies, polyphonic pieces), with a final cross-dataset experiment revealing model performance on unseen data.
                The results indicate that current CNN models need further optimization methods, i.e. domain adaptation, to increase generalization capability.</li>

                <li>In our second paper, we introduce a novel collection of educational material for teaching and learning fundamentals of music processing (FMP) with a particular focus on the audio domain.
                  This collection is referred to as FMP notebooks, which include open-source Python code, Jupyter notebooks, detailed explanations, as well as numerous audio and music examples for teaching and learning MIR and audio signal processing.
                  The notebooks are accessible at <a href="https://www.audiolabs-erlangen.de/FMP" target="_blank">https://www.audiolabs-erlangen.de/FMP</a>.
                </li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>

  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="ICASSP-2018">ICASSP 2019</h2>

          <blockquote class="blockquote"> We are glad to anounce that three papers from the ISAD project have been accepted for at the 44th nternational Conference on Acoustics, Speech, and Signal Processing (ICASSP 2019) in Brighton (UK).</blockquote>
          <ul>
            <li>The first paper compares hand-crafted feature sets for fundamental frequency contour classification with automatically learnt feature representations based on convolutional neural networks.
              The evaluation scenarios include different tasks such as classifying music instruments, playing techniques, as well as music genres.
              The results show a comparable performance of both feature sets. Interestingly, the automatically learnt features show a higher degree of redundancy since multiple convolution kernels (filters) specialize on similar contour shapes. </li>

            <li>Our second paper investigates transitions between subsequent chords within a piece, extracted from audio recordings. We propose novel mid-level features that capture chord transitions in a &#8220;soft&#8221; way. Our method exploits the Baum&ndash;Welch algorithm, which does not involve hard decisions on chord labels.  In several experiments, we evaluate these features within a style classification scenario discriminating four historical periods of Western classical music.</li>

            <li>In our third paper, we consider the cross-modal retrieval scenario of finding short monophonic musical themes in symbolic format within audio recordings of Western classical music.
              We propose to perform the cross-modal comparison on the basis of melody-enhanced salience representations.
              As the main contribution, we evaluate several conceptually different salience representations for our cross-modal retrieval scenario.</li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>

  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="ISMIR-2018">ISMIR 2018</h2>

          <blockquote class="blockquote"> We are glad to anounce that our three papers have been accepted for presentation at the 19th Conference of the International Society for Music Information Retrieval, which takes place in Paris.</blockquote>
          <ul>
            <li>The first paper re-considers a method for analyzing the tonal complexity of music recordings within a whole corpus. We transfer such a study - which have shown interesting results for Western classical music - to a jazz music
              scenario using the Weimar Jazz Database (WJD). Based on the audio recordings as well as the high-quality transcriptions of the WJD, we investigate the influence of the input representation type on the corpus-level observations. </li>

            <li>Our second paper investigates two approaches to improve a bass pitch detection algorithm based on deep neural networks.
              First, we show that by adding isolated recordings of the targeted instrument (upright bass) to the training set, we can improve the accuracy.
              Second, we increase the amount of training data by adding unannotated audio data, for which we obtain bass pitch annotations via label propagation. </li>

            <li>In our third paper we focus on predominant melody instrument recognition in ensemble recordings of popular and jazz music.
              First, we investigate, how source separation techniques for separating harmonic / percussive signal components or for extracting the main melody instrument from a mixture can be used as pre-processing step.
              Second, we evaluate transfer / continuous learning to obtain specified models for tasks such as jazz solo instrument recognition from models, which were trained on a larger set of instruments before. </li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>

  <hr>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            <li class="list-inline-item">
              <a href="https://github.com/dfg-isad">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://twitter.com/ISAD35745134">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <p class="copyright text-muted">Informed Sound Activity Detection
            in Music Recordings (ISAD) &copy; 2018</p>
        </div>
      </div>
    </div>
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/clean-blog.min.js"></script>

</body>

</html>
