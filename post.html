<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>ISAD - Posts and Anouncements</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">

  <!-- Custom styles for this template -->
  <link href="css/clean-blog.min.css" rel="stylesheet">

</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="navbar-collapse collapse w-100 order-1 order-md-0 dual-collapse2">
      <!-- nothing left aligned -->
    </div>

    <div class="collapse navbar-collapse mx-auto order-0" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="about.html">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="post.html">Anouncements</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="publications.html">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="researchers.html">Researchers</a>
        </li>
      </ul>
    </div>

    <div class="navbar-collapse collapse w-100 order-3 dual-collapse2">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a href="http://www.dfg.de" target="_blank" style="padding-right:5px">
            <img src="img/logo_dfg.svg" style="height:25px" alt="DFG">
          </a>
          <a href="https://www.audiolabs-erlangen.de/fau/professor/mueller" target="_blank" style="padding:5px">
            <img src="img/logo_fau.svg" style="height:25px" alt="FAU">
          </a>
          <a href="https://www.audiolabs-erlangen.de" target="_blank" style="padding:5px">
            <img src="img/logo_alabs.svg" style="height:25px" alt="AudioLabs">
          </a>
          <a href="https://www.idmt.fraunhofer.de/" target="_blank" style="padding:5px">
            <img src="img/logo_idmt.svg" style="height:25px" alt="IDMT">
          </a>
        </li>
      </ul>
    </div>
  </nav>

  <!-- Page Header -->
  <header class="masthead" style="background-color:#F8F8F8;">
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="page-heading">
            <h2>News about ISAD</h2>
            <span class="subheading"></span>
          </div>
        </div>
      </div>
    </div>
  </header>

  <!-- Post Content -->
  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="MDPI-2021">Electronics: Special Issue Machine Learning Applied to Music/Audio Signal Processing 2021</h2>

          <blockquote class="blockquote">Two journals from the ISAD project have been accepted for the MDPI Electronics Journal, Special Issue: Machine Learning Applied to Music/Audio Signal Processing.</blockquote>
          <ul>
            <li>The first journal is titled "Jazz Bass Transcription Using a U-Net Architecture", and can be found <a href="https://www.mdpi.com/2079-9292/10/6/670">here</a>. </li>

            <li>The second journal is titled "Informing Piano Multi-Pitch Estimation with Inferred Local Polyphony Based on Convolutional Neural Networks", and can be found <a href="https://www.mdpi.com/2079-9292/10/7/851">here</a>.</li>
          </ul>
          For more details please refer to our <a href="publications.html">publications</a> section.
        </div>
      </div>
    </div>
  </article>
    

  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="ISMIR-2020">ISMIR 2020</h2>

          <blockquote class="blockquote">Two papers from the ISAD project have been accepted for the 21st Conference of the International Society for Music Information Retrieval (ISMIR 2020) in Montréal, Canada.</blockquote>
          <ul>
            <li>The paper titled "Using Weakly Aligned Score–Audio Pairs to Train Deep Chroma Models for Cross-Modal Music Retrieval" shows how to use the Connectionist Temporal Classification (CTC) loss to train a deep learning model for computing an enhanced chroma representation, using weakly aligned score–audio pairs. We then apply this model to a cross-modal retrieval task, where we aim to find relevant audio recordings of Western classical music, given a short monophonic musical theme in symbolic notation as a query. We present systematic experiments that show improved state-of-the-art results for this theme-based retrieval task.</li>

            <li>In our second paper, titled "Classifying Leitmotifs in Recordings of Operas by Richard Wagner", we approach the task of classifying leitmotifs in audio recordings. Such leitmotifs (short musical ideas referring to semantic entities such as characters, places, items, or feelings) are used by composers of Western opera for guiding the audience through the plot and illustrating the events on stage. Our findings demonstrate the possibilities and limitations of leitmotif classification in audio recordings and pave the way towards the fully automated detection of leitmotifs in music recordings.
            </li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>


    <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="AS-2020">Applied Sciences 2020</h2>

          <blockquote class="blockquote">An article from ISAD has been accepted for publication in the Special Issue on Digital Audio Effects of the Applied Sciences journal. </blockquote>
          <ul>
            <li>Cross-version music retrieval aims at identifying all versions of a given piece of music using a short query audio fragment. One previous approach, which is particularly suited for Western classical music, is based on a nearest neighbor search using short sequences of chroma features, also referred to as audio shingles. From the viewpoint of efficiency, indexing and dimensionality reduction are important aspects. In this paper, we extend previous work by adapting two embedding techniques; one is based on classical principle component analysis, and the other is based on neural networks with triplet loss. Furthermore, we report on systematically conducted experiments with Western classical music recordings and discuss the trade-off between retrieval quality and embedding dimensionality. As one main result, we show that, using neural networks, one can reduce the audio shingles from 240 to fewer than 8 dimensions with only a moderate loss in retrieval accuracy. In addition, we present extended experiments with databases of different sizes and different query lengths to test the scalability and generalizability of the dimensionality reduction methods. We also provide a more detailed view into the retrieval problem by analyzing the distances that appear in the nearest neighbor search.
            </li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>

    <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="TASLP-2019">IEEE/ACM TASLP 2019</h2>

          <blockquote class="blockquote">An article from ISAD has been accepted for publication at the IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP). </blockquote>
          <ul>
            <li> Ever wondered what deep neural networks learn when they are trained to isolate the signing voice? Our work entitled "Examining the Mapping Functions of Denoising Autoencoders in Singing Voice Separation" proposes a method to analyze deep models, with a signal processing twist. That twist brings the notion of a well established signal processing operation, that is filtering, allowing the intuitive examination of such deep models.

            </li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>

  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="ISMIR-2019">ISMIR 2019</h2>

          <blockquote class="blockquote">Two papers from the ISAD project have been accepted for the 20th Conference of the International Society for Music Information Retrieval (ISMIR 2019) in Delft, NL.</blockquote>
          <ul>
            <li>The paper titled "Investigating CNN-Based Instrument Family Recognition for Western Classical Music Recordings" analyzes the influence of data normalization, patch pre-processing and augmentation techniques on the generalization capabilities of CNN models.
                Experiments are conducted on three datasets covering different levels of timbral complexity (isolated notes, isolated melodies, polyphonic pieces), with a final cross-dataset experiment revealing model performance on unseen data.
                The results indicate that current CNN models need further optimization methods, i.e. domain adaptation, to increase generalization capability.</li>

                <li>In our second paper, we introduce a novel collection of educational material for teaching and learning fundamentals of music processing (FMP) with a particular focus on the audio domain.
                  This collection is referred to as FMP notebooks, which include open-source Python code, Jupyter notebooks, detailed explanations, as well as numerous audio and music examples for teaching and learning MIR and audio signal processing.
                  The notebooks are accessible at <a href="https://www.audiolabs-erlangen.de/FMP" target="_blank">https://www.audiolabs-erlangen.de/FMP</a>.
                </li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>

  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="ICASSP-2018">ICASSP 2019</h2>

          <blockquote class="blockquote"> We are glad to anounce that three papers from the ISAD project have been accepted for at the 44th nternational Conference on Acoustics, Speech, and Signal Processing (ICASSP 2019) in Brighton (UK).</blockquote>
          <ul>
            <li>The first paper compares hand-crafted feature sets for fundamental frequency contour classification with automatically learnt feature representations based on convolutional neural networks.
              The evaluation scenarios include different tasks such as classifying music instruments, playing techniques, as well as music genres.
              The results show a comparable performance of both feature sets. Interestingly, the automatically learnt features show a higher degree of redundancy since multiple convolution kernels (filters) specialize on similar contour shapes. </li>

            <li>Our second paper investigates transitions between subsequent chords within a piece, extracted from audio recordings. We propose novel mid-level features that capture chord transitions in a &#8220;soft&#8221; way. Our method exploits the Baum&ndash;Welch algorithm, which does not involve hard decisions on chord labels.  In several experiments, we evaluate these features within a style classification scenario discriminating four historical periods of Western classical music.</li>

            <li>In our third paper, we consider the cross-modal retrieval scenario of finding short monophonic musical themes in symbolic format within audio recordings of Western classical music.
              We propose to perform the cross-modal comparison on the basis of melody-enhanced salience representations.
              As the main contribution, we evaluate several conceptually different salience representations for our cross-modal retrieval scenario.</li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>

  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">

          <h2 class="section-heading" id="ISMIR-2018">ISMIR 2018</h2>

          <blockquote class="blockquote"> We are glad to anounce that our three papers have been accepted for presentation at the 19th Conference of the International Society for Music Information Retrieval, which takes place in Paris.</blockquote>
          <ul>
            <li>The first paper re-considers a method for analyzing the tonal complexity of music recordings within a whole corpus. We transfer such a study - which have shown interesting results for Western classical music - to a jazz music
              scenario using the Weimar Jazz Database (WJD). Based on the audio recordings as well as the high-quality transcriptions of the WJD, we investigate the influence of the input representation type on the corpus-level observations. </li>

            <li>Our second paper investigates two approaches to improve a bass pitch detection algorithm based on deep neural networks.
              First, we show that by adding isolated recordings of the targeted instrument (upright bass) to the training set, we can improve the accuracy.
              Second, we increase the amount of training data by adding unannotated audio data, for which we obtain bass pitch annotations via label propagation. </li>

            <li>In our third paper we focus on predominant melody instrument recognition in ensemble recordings of popular and jazz music.
              First, we investigate, how source separation techniques for separating harmonic / percussive signal components or for extracting the main melody instrument from a mixture can be used as pre-processing step.
              Second, we evaluate transfer / continuous learning to obtain specified models for tasks such as jazz solo instrument recognition from models, which were trained on a larger set of instruments before. </li>
          </ul>
          For more details please refer to our <a href="publications.html"> publications</a> section.
        </div>
      </div>
    </div>
  </article>

  <hr>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            <li class="list-inline-item">
              <a href="https://github.com/dfg-isad">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://twitter.com/ISAD35745134">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <p class="copyright text-muted">Informed Sound Activity Detection
            in Music Recordings (ISAD) &copy; 2018</p>
        </div>
      </div>
    </div>
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/clean-blog.min.js"></script>

</body>

</html>
